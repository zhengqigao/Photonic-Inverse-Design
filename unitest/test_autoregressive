import argparse
import os
from typing import Callable, Dict, Iterable, List, Tuple
import torch.cuda.amp as amp
import mlflow
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from pyutils.config import configs
from pyutils.general import AverageMeter, logger as lg
from pyutils.loss import KLLossMixed
from pyutils.torch_train import (
    BestKModelSaver,
    count_parameters,
    get_learning_rate,
    load_model,
    set_torch_deterministic,
)
from pyutils.typing import Criterion, DataLoader, Optimizer, Scheduler
import torch.fft
from core import builder
from core.datasets.mixup import Mixup, MixupAll
from core.utils import DeterministicCtx, normalize, make_axes_locatable, plot_compare, print_stat
import matplotlib.pyplot as plt
from torch import Tensor
import h5py
import yaml
import random

def resize_and_pad_to_square(image: Tensor, image_size: int = 512, resolution: float = 20.0):
    """Resizes an image to a square with constant padding, maintaining aspect ratio.

    Args:
        image: A PyTorch tensor of shape (C, H, W) representing the image.
        image_size: The desired size of the square image.

    Returns:
        A PyTorch tensor of shape (C, image_size, image_size) representing the resized and padded image.
    """

    # Determine the longer dimension of the original image
    max_dim = max(image.size(-1), image.size(-2))

    # Calculate the scaling ratio
    scaling_factor = image_size / max_dim

    # Resize the image based on the scaling factor
    new_size = (int(round(image.size(-2) * scaling_factor)), int(round(image.size(-1) * scaling_factor)))
    # print(image.size(), new_size)
    image = image.unsqueeze(0)
    resized_image = torch.nn.functional.interpolate(image, size=new_size, mode="bilinear")
    # print(resized_image.shape)
    # Calculate the padding needed to make the image square
    padding = (image_size - resized_image.size(-2), image_size - resized_image.size(-1))
    lower, upper = padding[0] // 2, padding[0] - padding[0] // 2
    left, right = padding[1] // 2, padding[1] - padding[1] // 2
    # print(padding)

    # Pad the image with constant padding
    padded_image = torch.nn.functional.pad(resized_image, (left, right, lower, upper), value=image[0, 0, 1, 1], mode='constant')[0]
    grid_step = 1 / resolution / scaling_factor
    # assert padded_image.shape[1] == padded_image.shape[2] == image_size, f"{padded_image.shape[1]} != {padded_image.shape[2]} != {image_size}"
    return padded_image, torch.tensor([grid_step])

def test_autoregressive(model, cfg, file_names, num_begin_time, criterion, device, video_length, dir="./data/fdtd/raw_long"):
    model.eval()
    loss_list = []
    with DeterministicCtx(42):
        for file_name in file_names:
            for j in range(num_begin_time):
                # device_files, start, time_anchor, self.offset_frames = self.data[item]
                with open(os.path.join(dir, file_name).replace(".h5", ".yml"), "r") as f:
                    meta = yaml.safe_load(f)
                    sources = meta["sources"][-1:]
                    resolution = meta["simulation"]["resolution"] # e.g., 20 pixels per um
                    PML = meta["simulation"]["PML"]
                    eps_bg = meta["device"]["cfg"]["eps_bg"]
                with h5py.File(os.path.join("./data/fdtd", "raw_long", file_name), "r") as f:
                    eps = torch.from_numpy(f["eps"][()]).float()[None, ] # [1, 650, 243]
                    Ez = torch.from_numpy(f["Ez"][:][()]).float() # [833, 650, 243] -> [offset+out, 650, 243]
                    print("this is the shape of Ez: ", Ez.shape)
                    # Ez = Ez[600:((len(Ez)-cfg.dataset.in_frames)//600)*600+cfg.dataset.in_frames] # [n*600+8, 650, 243]
                    begin_time = random.randint(0, len(Ez)-cfg.dataset.in_frames-1-video_length)
                    Ez = Ez[begin_time: begin_time+10+video_length]
                
                source = torch.zeros_like(Ez)
                for src in sources:
                    center = src["src_center"] # um [-1, 0.1, 0]
                    size = src["src_size"] # um [0, 2, 0]
                    # print(center, size)
                    center = [int(round(i * resolution)) for i in center] # pixel [-20, 2, 0]
                    size = [int(round(i * resolution)) for i in size] # [0, 40, 0]
                    # print(center, size)
                    left, right = max(0, source.shape[1]//2 + center[0] - 5 - size[0]//2), source.shape[1]//2 + center[0] + 5 + size[0]//2
                    lower, upper = max(0, source.shape[2]//2 + center[1] - 5 - size[1]//2), source.shape[2]//2 + center[1] + 5 + size[1]//2
                    # print(left, right, lower, upper)
                    # print()
                    source[:, left:right, lower:upper] = Ez[:, left:right, lower:upper]
                    src_mask = torch.zeros(Ez.shape[-2:])[None, ...]
                    src_mask[:, left:right, lower:upper] = 1

                data = {
                    "eps": eps.sqrt(), # we want to use index here, not permittivity, index is smaller
                    "eps_bg": torch.tensor([eps_bg]),
                    "source": source[cfg.dataset.in_frames:], # now source is 600*n, h, w
                    "Ez": Ez[:cfg.dataset.in_frames], # now Ez is 8, h, w
                    "src_mask": src_mask, # now src_mask is 1, h, w
                    "scaling_factor": torch.tensor([256/534.75])
                }
                target = {
                    "Ez": Ez[cfg.dataset.in_frames:], # now target is 600*n, h, w
                }
                if file_name.startswith("mrr"):
                    newSize = (int(round(data["Ez"].shape[-2]*data["scaling_factor"].item())),
                            int(round(data["Ez"].shape[-1]*data["scaling_factor"].item())),)
                elif file_name.startswith("mmi"):
                    newSize = (int(round(data["Ez"].shape[-2]*data["scaling_factor"].item()*0.75)),
                            int(round(data["Ez"].shape[-1]*data["scaling_factor"].item()*0.75)),)
                    data["eps"] = data["eps"]
                # no need to pad the data now since there is only one test case in this case and it is a mrr with up to 10000 time steps
                # just resize it the newSize so that the model could see the same wavelength
                # remember to scale the eps
                data["Ez"] = torch.nn.functional.interpolate(data["Ez"].unsqueeze(0), size=newSize, mode="bilinear").squeeze(0) # dummy batch dim and then remove it
                data["eps"] = torch.nn.functional.interpolate(data["eps"].unsqueeze(0), size=newSize, mode="bilinear").squeeze(0)
                data["source"] = torch.nn.functional.interpolate(data["source"].unsqueeze(0), size=newSize, mode="bilinear").squeeze(0)
                data["src_mask"] = torch.nn.functional.interpolate(data["src_mask"].unsqueeze(0), size=newSize, mode="bilinear").squeeze(0)
                data["effective_region_mask"] = torch.ones((1, 1, data["Ez"].shape[-2], data["Ez"].shape[-1])).to(device)
                target["Ez"] = torch.nn.functional.interpolate(target["Ez"].unsqueeze(0), size=newSize, mode="bilinear").squeeze(0)

                if "fno" in cfg.model.name.lower(): # if we are now test the FNO, we need to padding the data to 256*256
                    maxHight = 256
                    maxWidth = 256
                    hightPatchSize_bot = (maxHight-data["Ez"].shape[-2])//2
                    hightPatchSize_top = maxHight-data["Ez"].shape[-2]-(maxHight-data["Ez"].shape[-2])//2
                    widthPatchSize_left = (maxWidth-data["Ez"].shape[-1])//2
                    widthPatchSize_right = maxWidth-data["Ez"].shape[-1]-(maxWidth-data["Ez"].shape[-1])//2

                    data["Ez"] = torch.nn.functional.pad(data["Ez"], (widthPatchSize_left, widthPatchSize_right, hightPatchSize_bot, hightPatchSize_top), mode='constant', value=0)
                    data["eps"] = torch.nn.functional.pad(data["eps"], (widthPatchSize_left, widthPatchSize_right, hightPatchSize_bot, hightPatchSize_top), mode='constant', value=data["eps_bg"].item())
                    data["source"] = torch.nn.functional.pad(data["source"], (widthPatchSize_left, widthPatchSize_right, hightPatchSize_bot, hightPatchSize_top), mode='constant', value=0)
                    data["src_mask"] = torch.nn.functional.pad(data["src_mask"], (widthPatchSize_left, widthPatchSize_right, hightPatchSize_bot, hightPatchSize_top), mode='constant', value=0)
                    data["effective_region_mask"] = torch.nn.functional.pad(data["effective_region_mask"], (widthPatchSize_left, widthPatchSize_right, hightPatchSize_bot, hightPatchSize_top), mode='constant', value=0)
                        
                    target["Ez"] = torch.nn.functional.pad(target["Ez"], (widthPatchSize_left, widthPatchSize_right, hightPatchSize_bot, hightPatchSize_top), mode='constant', value=0)

                with torch.no_grad():
                    for key, d in data.items():
                        print("this is the key", key)
                        data[key] = d.to(device, non_blocking=True)
                    for key, t in target.items():
                        target[key] = t.to(device, non_blocking=True)
                    # add a batch dim
                    data["eps"] = data["eps"].unsqueeze(0)
                    data["Ez"] = data["Ez"].unsqueeze(0)
                    data["source"] = data["source"].unsqueeze(0)
                    data["src_mask"] = data["src_mask"].unsqueeze(0)
                    target["Ez"] = target["Ez"].unsqueeze(0)

                    print("this is the shape of the data", data["eps"].shape, data["Ez"].shape, data["source"].shape, data["src_mask"].shape)
                    print("this is the shape of the target", target["Ez"].shape)

                    eps = data["eps"]
                    input_fields = data["Ez"]
                    injected_fields = data["source"][:, :cfg.dataset.out_frames]
                    in_data = torch.cat(
                        [eps, input_fields, injected_fields], dim=1
                    )
                    result = []
                    print("this is the shape of the Ez", Ez.shape)
                    num_iters = (Ez.shape[0]-10)//cfg.dataset.out_frames
                    print("this is the number of iterations", num_iters)
                    local_autoreg_loss = []
                    with amp.autocast(enabled=False):
                        if cfg.run.test_mode == "pattern":
                            for iter_time in range(num_iters):
                                # print("this is the iteration time", iter_time)
                                output, normalization_factor = model(in_data, target["Ez"][:, iter_time*model.out_channels: (iter_time+1)*model.out_channels, ...], grid_step=1.55, src_mask=data["src_mask"], padding_mask = data["effective_region_mask"])
                                print(f"this is the SF at iter {iter_time}: ", normalization_factor[:, 0, ...].squeeze().item())
                                prediction = output*normalization_factor
                                result.append(prediction)
                                if iter_time != 0:
                                    normalization_factor_target = torch.abs(target["Ez"][:, iter_time*model.out_channels-model.in_frames: iter_time*model.out_channels, ...]).amax(dim=(1, 2, 3), keepdim=True) + 1e-6
                                    local_loss = criterion(output, target["Ez"][:, iter_time*model.out_channels: (iter_time+1)*model.out_channels, ...]/normalization_factor_target, data["effective_region_mask"])
                                    if cfg.plot.autoreg:
                                        dir_path = os.path.join(cfg.plot.root, cfg.checkpoint.model_comment)
                                        os.makedirs(dir_path, exist_ok=True)
                                        filepath = os.path.join(dir_path, f"iter_time-{iter_time}.png")
                                        plot_compare(
                                            epsilon=in_data[0, 0:1],
                                            input_fields=in_data[0, 1: -model.out_channels],
                                            pred_fields=output[0],
                                            target_fields=(target["Ez"][0, iter_time*model.out_channels: (iter_time+1)*model.out_channels]/normalization_factor_target).squeeze(0),
                                            filepath=filepath,
                                            pol="Ez",
                                            norm=False,
                                        )
                                else:
                                    local_loss = criterion(output, target["Ez"][:, iter_time*model.out_channels: (iter_time+1)*model.out_channels, ...]/normalization_factor, data["effective_region_mask"])
                                    if cfg.plot.autoreg:
                                        dir_path = os.path.join(cfg.plot.root, cfg.checkpoint.model_comment)
                                        os.makedirs(dir_path, exist_ok=True)
                                        filepath = os.path.join(dir_path, f"iter_time-{iter_time}.png")
                                        plot_compare(
                                            epsilon=in_data[0, 0:1],
                                            input_fields=in_data[0, 1: -model.out_channels],
                                            pred_fields=output[0],
                                            target_fields=(target["Ez"][0, iter_time*model.out_channels: (iter_time+1)*model.out_channels]/normalization_factor).squeeze(0),
                                            filepath=filepath,
                                            pol="Ez",
                                            norm=False,
                                        )
                                print(f"this is the local loss at iter {iter_time}", local_loss.item(), flush=True)
                                local_autoreg_loss.append(local_loss.item())
                                if iter_time == num_iters-1:
                                    break
                                # input_fields = torch.cat([input_fields, prediction], dim=1)[:, -model.in_frames:]
                                input_fields = torch.cat([input_fields, output], dim=1)[:, -model.in_frames:] # only compare the pattern
                                injected_fields = data["source"][:, (iter_time+1)*model.out_channels: (iter_time+2)*model.out_channels]
                                if iter_time != 0:
                                    injected_fields = injected_fields/normalization_factor_target
                                in_data = torch.cat([eps, input_fields, injected_fields], dim=1) # update the input fields
                                # print("this is the shape of the output", output.shape)
                                # print("this is the shape of the normalization factor", normalization_factor.shape)
                            total_video = torch.cat(result, dim=1)
                            total_loss = criterion(total_video, target["Ez"], torch.ones((1, 1, target["Ez"].shape[-2], target["Ez"].shape[-1])).to(device))
                            print("the following is the stat for the autoregressive whole video prediction")
                            print_stat(total_video)
                            print("this is the total loss", total_loss.item())
                            print("this is the local autoreg loss", local_autoreg_loss)
                            print("this is the average local autoreg loss", sum(local_autoreg_loss)/len(local_autoreg_loss))
                        elif cfg.run.test_mode == "whole_video":
                            for iter_time in range(num_iters):
                                output, normalization_factor = model(in_data, target["Ez"][:, iter_time*cfg.dataset.out_frames: (iter_time+1)*cfg.dataset.out_frames, ...], grid_step=1.55, src_mask=data["src_mask"], padding_mask = data["effective_region_mask"])
                                prediction = output*normalization_factor
                                if cfg.plot.autoreg:
                                    dir_path = os.path.join(cfg.plot.root, cfg.checkpoint.model_comment)
                                    os.makedirs(dir_path, exist_ok=True)
                                    port = file_name.rstrip(".h5").split("-")[-1]
                                    filepath = os.path.join(dir_path, f"port-{port}_begin_time_id-{j}_iter_time-{iter_time}.png")
                                    plot_compare(
                                        epsilon=in_data[0, 0:1],
                                        input_fields=in_data[0, 1: 1+model.in_frames],
                                        pred_fields=prediction[0],
                                        target_fields=(target["Ez"][0, iter_time*cfg.dataset.out_frames: (iter_time+1)*cfg.dataset.out_frames]).squeeze(0) if file_name.startswith("mrr") else target["Ez"][0, iter_time*cfg.dataset.out_frames: (iter_time+1)*cfg.dataset.out_frames],
                                        filepath=filepath,
                                        pol="Ez",
                                        norm=False,
                                        max_fields=10,
                                    )
                                result.append(prediction)
                                local_loss = criterion(output, target["Ez"][:, iter_time*cfg.dataset.out_frames: (iter_time+1)*cfg.dataset.out_frames, ...]/normalization_factor, data["effective_region_mask"])
                                local_autoreg_loss.append(local_loss.item())
                                ## update the source and the input fields for the next iteration
                                input_fields = torch.cat([input_fields, prediction], dim=1)[:, -model.in_frames:]
                                injected_fields = data["source"][:, (iter_time+1)*cfg.dataset.out_frames: (iter_time+2)*cfg.dataset.out_frames]
                                in_data = torch.cat([eps, input_fields, injected_fields], dim=1)
                            total_video = torch.cat(result, dim=1)
                            total_loss = criterion(total_video, target["Ez"], torch.ones((1, 1, target["Ez"].shape[-2], target["Ez"].shape[-1])).to(device))
                            print("this is the local autoreg loss", local_autoreg_loss, flush=True)
                            print("the following is the autoregressive loss of the whole video prediction: ", total_loss.item(), flush=True)
                            loss_list.append(np.array(local_autoreg_loss).mean())
                        else:
                            raise ValueError("Unsupported mode for the autoregressive test")
        print("Here we go! This is the total loss list", loss_list)
        print("Here we go! this is the average loss", np.array(loss_list).mean())

def plot_compare_local(
    epsilon: Tensor,
    input_fields: Tensor,
    pred_fields: Tensor,
    target_fields: Tensor,
    filepath: str,
    pol: str = "Ez",
    norm: bool = True,
    max_fields=32,
    if_colorbar = False,
    field_range = 0.25,
    error_range = 0.1,
) -> None:

    field_val = pred_fields.data.transpose(-1, -2).cpu().numpy()
    target_field_val = target_fields.data.transpose(-1, -2).cpu().numpy()
    input_field_val = input_fields.data.transpose(-1, -2).cpu().numpy()
    # eps_r = simulation.eps_r
    eps_r = epsilon.data.transpose(-1, -2).cpu().numpy()
    err_field_val = field_val - target_field_val
    # field_val = np.abs(field_val)
    field_val = field_val
    # target_field_val = np.abs(target_field_val)
    target_field_val = target_field_val
    err_field_val = np.abs(err_field_val)
    outline_val = np.abs(eps_r)

    # vmax = field_val.max()
    vmin = 0.0
    b = min(max(field_val.shape[0], input_field_val.shape[0]), max_fields)
    target_start = max(-field_val.shape[0], -max_fields)
    input_start = max(-input_field_val.shape[0], -max_fields)

    field_val = field_val[target_start:]
    target_field_val = target_field_val[target_start:]
    err_field_val = err_field_val[target_start:]
    input_field_val = input_field_val[input_start:]
    fig, axes = plt.subplots(4, b, constrained_layout=True, figsize=(3 * b, 8.1))
    if b == 1:
        axes = axes[..., np.newaxis]
    # cmap = "magma"
    cmap = "RdBu_r"
    # print(field_val.shape, target_field_val.shape, outline_val.shape)
    zeros = torch.zeros_like(target_fields[0]).cpu().numpy()
    for i in range(b):
        vmax = np.max(np.abs(target_field_val[i])) if i < target_field_val.shape[0] else 0.1
        h0 = axes[0, i].imshow(input_field_val[i] if i < input_field_val.shape[0] else zeros, cmap=cmap, vmin=-vmax, vmax=vmax, origin="lower")
        if norm:
            h1 = axes[2, i].imshow(normalize(field_val[i]) if i < field_val.shape[0] else zeros, cmap=cmap, origin="lower")
            h2 = axes[1, i].imshow(normalize(target_field_val[i]) if i < target_field_val.shape[0] else zeros, cmap=cmap, origin="lower")
        else:
            h1 = axes[2, i].imshow(field_val[i] if i < field_val.shape[0] else zeros, cmap=cmap, vmin=-field_range, vmax=field_range, origin="lower")
            h2 = axes[1, i].imshow(target_field_val[i] if i < target_field_val.shape[0] else zeros, cmap=cmap, vmin=-field_range, vmax=field_range, origin="lower")
        h3 = axes[3, i].imshow(err_field_val[i] if i < err_field_val.shape[0] else zeros, cmap=cmap, vmin=-error_range, vmax=error_range, origin="lower")
        if if_colorbar:
            for j in range(4):
                divider = make_axes_locatable(axes[j, i])
                cax = divider.append_axes("right", size="5%", pad=0.05)

                fig.colorbar([h0, h1, h2, h3][j], label=pol, ax=axes[j, i], cax=cax)
 
        # fig.colorbar(h2, label=pol, ax=axes[1,i])
        # fig.colorbar(h3, label=pol, ax=axes[2,i])

    # Do black and white so we can see on both magma and RdBu
    for ax in axes.flatten():
        ax.contour(outline_val[0], levels=2, linewidths=1.0, colors="w")
        ax.contour(outline_val[0], levels=2, linewidths=0.5, colors="k")
        ax.set_xticks([])
        ax.set_yticks([])
    # set_ms()
    plt.savefig(filepath, dpi=150)
    plt.close()


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("config", metavar="FILE", help="config file")
    # parser.add_argument('--run-dir', metavar='DIR', help='run directory')
    # parser.add_argument('--pdb', action='store_true', help='pdb')
    args, opts = parser.parse_known_args()

    configs.load(args.config, recursive=True)
    configs.update(opts)

    if torch.cuda.is_available() and int(configs.run.use_cuda):
        torch.cuda.set_device(configs.run.gpu_id)
        device = torch.device("cuda:" + str(configs.run.gpu_id))
        torch.backends.cudnn.benchmark = True
    else:
        device = torch.device("cpu")
        torch.backends.cudnn.benchmark = False

    if "backbone_cfg" in configs.model.keys():
        if configs.model.backbone_cfg.conv_cfg.type == "Conv2d" or configs.model.backbone_cfg.conv_cfg.type == "LargeKernelConv2d":
            if "r" in configs.model.backbone_cfg.conv_cfg.keys():
                del configs.model.backbone_cfg.conv_cfg["r"]
            if "is_causal" in configs.model.backbone_cfg.conv_cfg.keys():
                del configs.model.backbone_cfg.conv_cfg["is_causal"]
            if "mask_shape" in configs.model.backbone_cfg.conv_cfg.keys():
                del configs.model.backbone_cfg.conv_cfg["mask_shape"]
            if "enable_padding" in configs.model.backbone_cfg.conv_cfg.keys():
                del configs.model.backbone_cfg.conv_cfg["enable_padding"]

    model = builder.make_model(
        device,
        int(configs.run.random_state) if int(configs.run.deterministic) else None,
    )
    lg.info(model)

    test_criterion = builder.make_criterion(
        configs.test_criterion.name, configs.test_criterion
    ).to(device)

    load_model(
        model,
        configs.checkpoint.restore_checkpoint,
        ignore_size_mismatch=int(configs.checkpoint.no_linear),
    )
    print("model loaded successfully!", flush=True)
    test_autoregressive(model, configs, ('mmi_3x3_L_random-12345-p0.h5', 'mmi_3x3_L_random-12345-p1.h5', 'mmi_3x3_L_random-12345-p2.h5'), 20, test_criterion, device, 160, dir="./data/fdtd/raw_long")

if __name__ == "__main__":
    main()