{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "def print_stat(x, dist=False):\n",
    "    total_number = None\n",
    "    distribution = None\n",
    "    if dist:\n",
    "        total_number = x.numel()\n",
    "        distribution = torch.histc(x, bins=10, min=float(x.min()), max=float(x.max()))\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        print(\n",
    "            f\"min = {x.min().data.item():-15f} max = {x.max().data.item():-15f} mean = {x.mean().data.item():-15f} std = {x.std().data.item():-15f}\\n total num = {total_number} distribution = {distribution}\"\n",
    "        )\n",
    "    elif isinstance(x, np.ndarray):\n",
    "        print(\n",
    "            f\"min = {np.min(x):-15f} max = {np.max(x):-15f} mean = {np.mean(x):-15f} std = {np.std(x):-15f}\"\n",
    "        )\n",
    "        \n",
    "class MyLayerNorm(nn.Module):\n",
    "    r\"\"\"LayerNorm implementation used in ConvNeXt\n",
    "    LayerNorm that supports two data formats: channels_last (default) or channels_first.\n",
    "    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with\n",
    "    shape (batch_size, height, width, channels) while channels_first corresponds to inputs\n",
    "    with shape (batch_size, channels, height, width).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        normalized_shape,\n",
    "        eps=1e-6,  # TODO use small dataset to find if -6 is a good order of magnitude\n",
    "        data_format=\"channels_last\",\n",
    "        reshape_last_to_first=False,\n",
    "        interpolate=False,\n",
    "        is_linear: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        self.eps = eps\n",
    "        self.data_format = data_format\n",
    "        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n",
    "            raise NotImplementedError\n",
    "        self.normalized_shape = (normalized_shape,)\n",
    "        self.reshape_last_to_first = reshape_last_to_first\n",
    "        self.interpolate = interpolate\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.data_format == \"channels_last\":\n",
    "            return F.layer_norm(\n",
    "                x, self.normalized_shape, self.weight, self.bias, self.eps\n",
    "            )\n",
    "        elif self.data_format == \"channels_first\":\n",
    "            u = x.mean(1, keepdim=True)\n",
    "            s = (x - u).pow(2).mean(1, keepdim=True)\n",
    "            x = (x - u) / torch.sqrt(s + self.eps)\n",
    "            if self.interpolate:\n",
    "                weight = self.weight.unsqueeze(0).unsqueeze(0)\n",
    "                weight = F.interpolate(\n",
    "                    weight, size=x.shape[1], mode=\"linear\", align_corners=True\n",
    "                )\n",
    "                weight = weight.squeeze()\n",
    "                bias = self.bias.unsqueeze(0).unsqueeze(0)\n",
    "                bias = F.interpolate(\n",
    "                    bias, size=x.shape[1], mode=\"linear\", align_corners=True\n",
    "                )\n",
    "                bias = bias.squeeze()\n",
    "            else:\n",
    "                weight = self.weight\n",
    "                bias = self.bias\n",
    "            if len(x.shape) == 4:\n",
    "                x = weight[:, None, None] * x + bias[:, None, None]\n",
    "            elif len(x.shape) == 5:\n",
    "                x = weight[:, None, None, None] * x + bias[:, None, None, None]\n",
    "            elif len(x.shape) == 2:\n",
    "                x = weight[:] * x + bias[:]\n",
    "            return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        s = \"eps=\" + str(self.eps)\n",
    "        s += \", data_format=\" + str(self.data_format)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min =       -1.702983 max =        5.690491 mean =       -0.000000 std =        1.000002\n",
      " total num = None distribution = None\n",
      "min =       -1.122204 max =        5.745362 mean =        0.000000 std =        1.000002\n",
      " total num = None distribution = None\n",
      "min =       -1.094324 max =        5.675197 mean =        0.000000 std =        1.000002\n",
      " total num = None distribution = None\n",
      "min =       -1.097608 max =        5.702815 mean =       -0.000000 std =        1.000002\n",
      " total num = None distribution = None\n",
      "min =       -1.095659 max =        5.714510 mean =       -0.000000 std =        1.000002\n",
      " total num = None distribution = None\n"
     ]
    }
   ],
   "source": [
    "test_conv2d = nn.Sequential(\n",
    "    nn.Conv2d(50, 50, 3, padding=1, bias=True),\n",
    "    nn.Conv2d(50, 50, 3, padding=1, groups=50, bias=True),\n",
    "    nn.GELU(),\n",
    "    MyLayerNorm(50, data_format=\"channels_first\", eps=0),\n",
    "    )\n",
    "random_seed = 1234\n",
    "torch.manual_seed(random_seed)\n",
    "input_tensor = torch.randn(1, 50, 64, 64)\n",
    "input0p1 = input_tensor*0.1\n",
    "input0p5 = input_tensor*0.5\n",
    "input5 = input_tensor*5\n",
    "input10 = input_tensor*10\n",
    "out = test_conv2d(input_tensor)\n",
    "out0p1 = test_conv2d(input0p1)\n",
    "out0p5 = test_conv2d(input0p5)\n",
    "out5 = test_conv2d(input5)\n",
    "out10 = test_conv2d(input10)\n",
    "print_stat(out0p1)\n",
    "print_stat(out0p5)\n",
    "print_stat(out)\n",
    "print_stat(out5)\n",
    "print_stat(out10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
